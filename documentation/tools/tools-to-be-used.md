
# BioQuery â€” Tool Registry (Input/Output Specifications)

Each tool is defined as a callable component within the modelâ€™s orchestration layer.  
Tools may be invoked dynamically by the LLM or manually by users through the chat interface.

---

### ğŸ§¾ `create_document`

**Purpose:** Create and store a document artifact.  
**Inputs:**

- `title` _(string)_ â€” document title
    
- `body` _(string)_ â€” main textual content
    
- `image_prompt` _(optional string)_ â€” optional image description to generate accompanying visual
    
- `tags` _(array[string])_ â€” topic identifiers (e.g., `["microgravity", "stem cells"]`)
    

**Outputs:**

- `doc_id` _(string)_ â€” unique document identifier
    
- `title` _(string)_
    
- `body` _(string)_
    
- `image_link` _(string | null)_ â€” URL to generated image
    
- `tags` _(array[string])_
    

---

### ğŸ§¾ `update_document`

**Purpose:** Update an existing document artifact.  
**Inputs:**

- `doc_id` _(string)_ â€” reference to document in DB
    
- `title` _(optional string)_ â€” updated title
    
- `body` _(optional string)_ â€” updated content
    
- `tags` _(optional array[string])_ â€” updated tags
    

**Outputs:**

- `doc_id` _(string)_ â€” updated document ID
    
- `status` _(string)_ â€” e.g. `"updated"`
    

---

### ğŸ–¼ï¸ `generate_image`

**Purpose:** Generate and store an image via Freepikâ€™s image API.  
**Inputs:**

- `prompt` _(string)_ â€” description of the image to generate
    
- `show_to_user` _(boolean)_ â€” whether to display the image inline in chat
    
- `tags` _(array[string])_ â€” topics related to image
    

**Outputs:**

- `image_uri` _(string)_ â€” URL to stored image
    
- `tags` _(array[string])_
    
- `show_to_user` _(boolean)_
    

---

### ğŸ§¬ `create_knowledge_graph_json`

**Purpose:** Create a structured graph representing relationships in research data.  
**Inputs:**

- `nodes` _(array[object])_ â€” e.g., `{ id, label, type }`
    
- `edges` _(array[object])_ â€” e.g., `{ source, target, relation }`
    
- `context` _(optional string)_ â€” background text or description
    
- `tags` _(array[string])_
    

**Outputs:**

- `graph_json` _(object)_ â€” valid knowledge graph schema
    
- `tags` _(array[string])_
    

---

### ğŸ“Š `create_visual_json`

**Purpose:** Create structured data for visualization.  
**Inputs:**

- `chart_type` _(enum: 'pie' | 'bar' | 'line')_
    
- `data_points` _(array[object])_ â€” `{ label, value }` pairs
    
- `title` _(string)_
    
- `tags` _(array[string])_
    

**Outputs:**

- `visual_json` _(object)_ â€” structured dataset
    
- `chart_type` _(string)_
    
- `tags` _(array[string])_
    

---

### ğŸ–¼ï¸ `analyze_image`

**Purpose:** Extract and interpret information from an uploaded image.  
**Inputs:**

- `image_uri` _(string)_  
    **Outputs:**
    
- `analysis` _(string)_ â€” textual interpretation
    

---

### ğŸ“„ `analyze_document`

**Purpose:** Analyze uploaded documents (PDF, TXT, DOCX) for insights.  
**Inputs:**

- `file_uri` _(string)_
    
- `analysis_goal` _(optional string)_ â€” e.g. â€œsummarize results sectionâ€  
    **Outputs:**
    
- `summary` _(string)_
    
- `key_findings` _(array[string])_
    

---

### ğŸ•°ï¸ `timeline_builder`

**Purpose:** Generate a visual narrative or timeline.  
**Inputs:**

- `title` _(string)_
    
- `timeline_sections` _(array[object])_ â€” each with `{ title, description, image_prompt }`
    
- `tags` _(array[string])_
    

**Outputs:**

- `timeline_json` _(object)_ â€” array of `{ section_title, image_link, description }`
    
- `tags` _(array[string])_
    

---

### ğŸ” `contextual_search`

**Purpose:** Perform semantic retrieval from pgvector store.  
**Inputs:**

- `query` _(string)_
    
- `top_k` _(integer, default=5)_  
    **Outputs:**
    
- `results` _(array[object])_ â€” `{ title, text, url, similarity_score }`
    

---

### ğŸ’¬ `answer_with_sources`

**Purpose:** Generate a RAG-based answer with references.  
**Inputs:**

- `query` _(string)_
    
- `contextual_results` _(optional array)_ â€” can be passed from `contextual_search`  
    **Outputs:**
    
- `answer` _(string)_
    
- `sources` _(array[string])_ â€” reference URLs or PMCIDs
    

---

### ğŸŒ `translate_publication`

**Purpose:** Translate a document or text snippet to another language.  
**Inputs:**

- `text` _(string)_
    
- `target_lang` _(string, e.g., 'fr', 'es', 'de')_  

- `doc_uri` _(string); the URL of the document it processed_

    **Outputs:**
    
- `translated_text` _(string)_
    
- `detected_language` _(string)_

- `doc_uri` _(string); the URL of the document that was processed_    

---

## ğŸ”¹ Thoughts

The tools work together like this:

|Stage|Example Tools|
|---|---|
|**Preprocessing**|`analyze_document`, `analyze_image`|
|**Retrieval / RAG**|`contextual_search`, `answer_with_sources`|
|**Artifact Creation**|`create_document`, `update_document`, `timeline_builder`, `create_visual_json`, `create_knowledge_graph_json`|
|**Presentation / Extension**|`generate_image`, `translate_publication`|

This gives you a **modular, composable** AI system â€” you can build workflows like:

> â€œUser uploads a doc â†’ `analyze_document` â†’ `create_knowledge_graph_json` â†’ `generate_image` â†’ `create_document` (summary artifact) â†’ `pin_to_dashboard`.â€

The model's system prompts can be crafted to use this structure easy with proper co-ordination
